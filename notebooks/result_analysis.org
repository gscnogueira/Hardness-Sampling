#+title: Análise de Resultados (V2)

* Curvas de Ranking

Em primeiro lugar, fica visível que houve um maior overlap entre as curvas as bandas do que na versão anterior dos experimentos (V1).
Além disso, as bandas foram capazes de ocupar posições mais altas do que a versão antrior

| Classificador | Pior curva | Melhor Curva |
|---------------+------------+--------------|
| CART          | TU         | MS           |
| NB            | TU         | _CB_           |
| SVM           | _KDN_        | ID           |
| 5NN           | *Rnd*        | ID           |

- Nessa vez, CART e NB tiveram uma digerenciação maior em seus limites. Antes eles compartilhavam uma região maior das bandas, e agora, fica visível que CART possuiu pelo menos um resultado melhor que NB, ao longo de todos os resultados, ao passo que a distância entre seus limites inferiores aumentou. Esse aumento de distância é muito mais um indicativo que houve uma queda de desempenho nos métodos que utilizaram o NB, visto que antes eles estavam acima da linha 60, e agora estão abaixo
- É possivel ver que nesse caso o SVM é competivo, entretanto, ele precisa de mais iterações para apresentar melhores resultados. Mas é interessante observar que ele é a unica banda com uma tendencia de subida mais expressiva

* Rankings Médios

Segundo os testes, não tem como afimrar que qualquer método foi melhor que a amostragem aleatória, apenas que foi pior.

** Naive Bayes

*** Observações
- Aqui temos que praticamente todos os métodos foram superados pela *estratégia clássica* TU
- Apenas Rnd e LSR não podem ser ditos como ingeriores a TU
- Além disso, TU, Rnd e LSR foram melhor que todos os baselines com 99% de confiança
- F1I, CB e MV são piores que MS. Indicativo de que medidas baseadas em CB não são adequadas para esse aprendiz
- Melhor HM :: LSR
  
*** Colocações
1. TU
2. Rnd
3. LSR
4. TDU
5. kDN, LSCI, DCP, CLD, N1I
6. H, DS, TDP
7. N2I, CL, F4I, MS
8. 


** SVM
- Melhor HM :: kDN
- Nesse caso fica mais dificil de dizer quem é melhor, mas podemos perceber que alguns grupos de medidas se sobressairam em relação aos baselines.
- Não podemos dizer se esse grupo é melhor que Rnd ou MS, mas os experimentos mostram que seu desempenho foi melhor que o apresentado pelos outros baselines EERent, TU, e I, esses métodos são:
  - kDn
  - LSR
  - TDU
  - CLD
  - LSCI
  - DCP
  - CL
  - N1I
  - DS
- Além disso Kdn, LSR, TDU e CLD ficaram acima do desempenho de todas as medidas features based e class balance
** CART
- Melhor HM :: LSR
- Nesse caso as colocações ficaram mais bem definidas
- TU foi superior a praticamente todos, com excessão do Rnd (e a lSR com alpha>=0.05)
- Com excesão de LSR, LSCI e kDN, todas as outras pmedidas foram piores que Rnd
- LSR, LSCI, kdN, H, CL, f4I, CLD, N1I ficaram acima dos baselines
** 5NN
- Nesse caso foi mais dificil dizer quem foi o melhor, mas mesmo assim , a superioridade aos classifoc foi encontrada em alguns métodos
- Rnd, _TDu_, MS, _kDN_, _LSR_, _CLD_ foram melhores que os clássicos, além de melhores do que as medidas feature_based e class_balance
- DCP foi melhor do que EER, e ID,
- 

